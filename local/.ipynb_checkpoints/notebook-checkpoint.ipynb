{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import datastore\n",
    "\n",
    "datastore_client = datastore.Client(project='rareyetem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rainInfo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-dd443270bbde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mbob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbsList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0msmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbsList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrainInfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rainmm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrainInfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rainmm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rainInfo' is not defined"
     ]
    }
   ],
   "source": [
    "def fetchRain(startDate, endDate, province):\n",
    "    #print(province, startDate, endDate)\n",
    "    # performing province to stationID conversion, a bit costly\n",
    "    stationID = '327501'\n",
    "    stationFile = 'static/thailand_metstation.csv'\n",
    "    df = pd.read_csv(stationFile, dtype={\"province\": str, \"region\":str, \"stncode\":str})\n",
    "    df = df[df[\"province\"] == province]\n",
    "    for idx, row in df.iterrows():\n",
    "        stationID = row.stncode\n",
    "        break\n",
    "\n",
    "    #print('station id', stationID)\n",
    "    query = datastore_client.query(kind='stndate')\n",
    "    query.add_filter('stn', '=', stationID)\n",
    "    query.add_filter('date','>', startDate)\n",
    "    query.add_filter('date','<', endDate)\n",
    "    rain = query.fetch()\n",
    "    return rain\n",
    "\n",
    "def fetchSLA(startDate, endDate):\n",
    "    query = datastore_client.query(kind='date')\n",
    "    query.add_filter('date','>', startDate)\n",
    "    query.add_filter('date','<', endDate)\n",
    "    query.order = ['-date']\n",
    "    slas = query.fetch()\n",
    "    return slas\n",
    "\n",
    "# date is a key\n",
    "sDate = (datetime.now() - timedelta(365)).strftime('%Y-%m-%d')\n",
    "eDate = (datetime.now()).strftime('%Y-%m-%d')\n",
    "\n",
    "# populating training data\n",
    "provinces = pd.read_csv('static/thailand_metstation.csv', dtype={\"province\": str, \"region\":str, \"stncode\":str})\n",
    "\n",
    "\n",
    "# query bob and s-index from google cloud datastore\n",
    "sla = fetchSLA(sDate, eDate)\n",
    "bsIndex = {}\n",
    "for s in sla: # loop thru date\n",
    "    bsIndex[s['date']] = [s['bpos']-s['bneg'], s['spos']-s['sneg']] # indexes is a tuple\n",
    "\n",
    "#print(bsIndex)\n",
    "data = []\n",
    "for p in provinces.province: # for each date loop thru province\n",
    "    rain = fetchRain(sDate, eDate, p)\n",
    "    \n",
    "    stnId = 0\n",
    "    for r in rain:\n",
    "        stnId = r['stn']\n",
    "        break\n",
    "        \n",
    "    pLocation = provinces[provinces.stncode == stnId]\n",
    "    lat = pLocation.iloc[0].lat\n",
    "    lng = pLocation.iloc[0].lng\n",
    "    \n",
    "    rainInfo = {}\n",
    "    for r in rain:\n",
    "        rainInfo[r['date']] = r['rainmm']\n",
    "\n",
    "    # looping over days\n",
    "    for date, bsList in bsIndex.items():\n",
    "        bob = bsList[0]\n",
    "        smt = bsList[1]\n",
    "        print(rainInfo[date]['rainmm'])\n",
    "        try:\n",
    "            data.append([''.join(date.split('-')[1:]), bob, smt, lat, lng, rainInfo[date]['rainmm']])\n",
    "        except:\n",
    "            data.append([''.join(date.split('-')[1:]), bob, smt, lat, lng, 0.0])\n",
    "\n",
    "df = pd.DataFrame(np.array(data).reshape(27664,6), columns = ['date','bob','smt','lat','lng','rainmm'])\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# normalisation \n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "x_scaled[:,-1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled[:,-1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-03\n",
      "2020-04-11\n",
      "2020-04-15\n",
      "2020-04-25\n",
      "2020-04-26\n",
      "2020-04-27\n",
      "2020-04-28\n",
      "2020-04-29\n",
      "2020-05-01\n",
      "2020-05-03\n",
      "2020-05-08\n",
      "2020-05-10\n",
      "2020-05-15\n",
      "2020-05-18\n",
      "2020-05-19\n",
      "2020-05-20\n",
      "2020-05-21\n",
      "2020-05-27\n",
      "2020-05-28\n",
      "2020-05-29\n"
     ]
    }
   ],
   "source": [
    "# model training \n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 4,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}\n",
    "\n",
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "reg.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
